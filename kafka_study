aws zlrqhr32!
3.143.0.217
172.31.9.173
login as ec2-user

cd kafka_2.12-2.5.0 

*********자주사용 bin/실행.sh --서버 --명령어
bin/kafka-topics.sh --bootstrap-server my-kafka:9092
bin/kafka-topics.sh --bootstrap-server my-kafka:9092 --create --topic test --partitions 3 
--조회
bin/kafka-console-consumer.sh --bootstrap-server my-kafka:9092 --topic test --from-beginning 
bin/kafka-console-consumer.sh --bootstrap-server my-kafka:9092 --topic test --property print.key=true --property print.key.seperator="-" --from-beginning

--putty 
https://www.chiark.greenend.org.uk/~sgtatham/putty/
--jdk설치
sudo yum install -y java-1.8.0-openjdk-devel.x86_64
--kafka 설치
wget https://archive.apache.org/dist/kafka/2.5.0/kafka_2.12-2.5.0.tgz
tar xvf kafka_2.12-2.5.0.tgz
--heap
export KAFKA_HEAP_OPTS="-Xmx400m -Xms400m"
echo $KAFKA_HEAP_OPTS
--config
vi config/server.properties 
--주키퍼 실행
bin/zookeeper-server-start.sh -daemon config/zookeeper.properties

bin/kafka-console-producer.sh --bootstrap-server my-kafka:9092 --
bin/kafka-consumer-groups.sh --bootstrap-server my-kafka:9092 --


-- 명령어 모음

sudo yum install -y java-1.8.0-openjdk-devel.x86-64


전체 목록조회 bin/kafka-topics.sh --bootstrap-server my-kafka:9092



토픽 조회
bin/kafka-topics.sh --bootstrap-server my-kafka:9092 --list
bin/kafka-topics.sh --bootstrap-server my-kafka:9092 --describe --topic hello.kafka.2


--토픽 생성
bin/kafka-topics.sh --create --bootstrap-server my-kafka:9092 --topic hello.kafka
bin/kafka-topics.sh --create --bootstrap-server my-kafka:9092 --partitions 3 --replication-factor 1 --config retention.ms=172800000 --topic hello.kafka.2
bin/kafka-topics.sh --bootstrap-server my-kafka:9092 --create --topic test --partitions 3 
시간변경
bin/kafka-topics.sh --bootstrap-server my-kafka:9092 --topic hello.kafka --alter --partitions 4
bin/kafka-configs.sh --bootstrap-server my-kafka:9092 --entity-type topics --entity-name hello.kafka --alter --add-config retention.ms=86400000
bin/kafka-configs.sh --bootstrap-server my-kafka:9092 --entity-type topics --entity-name hello.kafka --describe  조회

--kafka-console-producer.sh 데이터를 보냄
bin/kafka-console-producer.sh --bootstrap-server my-kafka:9092 --topic hello.kafka

bin/kafka-console-producer.sh --bootstrap-server my-kafka:9092 --topic hello.kafka --property "parse.key=true" --property "key.separator=:"

--kafka-console-consumer.sh 데이터를 받음(파티션으로 부터 메세지를 가져간다)
bin/kafka-console-consumer.sh --bootstrap-server my-kafka:9092 --topic hello.kafka --from-beginning

--kafka-consumer-groups.sh

bin/kafka-consumer-groups.sh --bootstrap-server my-kafka:9092 --list 
bin/kafka-consumer-groups.sh --bootstrap-server my-kafka:9092 --group hello-group --describe

--verify
 bin/kafka-verifiable-producer.sh --bootstrap-server my-kafka:9092 --max-messages 10 --topic verify-test
 
--kafka-delete-records.sh
--삭제 데이터 생성
vi delete-topic.json
{"partitions":[{"topic": "test", "partition": 0, "offset":50}], "version":1}
-내용기록 후 아래 삭제명령어::
bin/kafka-delete-records.sh --bootstrap-server my-kafka:9092 --offset-json-file delete-topic.json

**
--로그보기
ls /tmp/kafka-logs

--zookeeper test
bin/zookeepe-shell.sh my-kafka:2181
ls /

get /brokers/ids/0

--토픽 이름 지정 (토픽 름은 변경되지 않음 -삭제 후 재생성)
토픽 작명의 템플릿과 예시
<환경>.<팀-명>.<애플리케이션-명>.<메시지-타입> prd.marketing-team.sms-platform.json
<프로젝트-명>.<서비스-명>.<환경>>.<이벤트-명> commerce.payment.prd.notification
<환경>.<서비스-명>.<JIRA-번호>.<메시지-타입> dev.email.sender.jira-1234.email-vo-custom
<카프카-클러스터-명>.<환경>.<서비스-명>.<메시지-타입> aws-kafka.live.marketing-platform.json

--java setting

--옵션 정리
producer
필수 
bootstrap.servers  통신 할 서버를 표기 , 1개이상 가능.보통 2개이상
key.serializer : 레코드의 메시지 키를 직렬화하는 클래스를 지정
value.serializer 레코드의 메시지 값을 직렬화하는 클래스를 지정
선택
acks  기본 값 1: 리더 파티션에 데이터가 저장되면 전송 성공, 0:프로듀서가 전송한 즉시 브로커에 데이터 저장 상관없이 성공, -1 or all: min.insync.replicas 개수에 해당하는 리더파티션과 팔로워 파티션에 데이터가 저장되면 성공
buffer.memory : 브로커로 전송할 데이터를 배치로 모으기 위함. 기본값 32mb
retries : 프로듀서가 브로커로 부터 에러를 받고 난 뒤 재전송을 시도하는 횟수 지정. 기본값 2147483647
batch.size배치로 전송할 레코드 최대 용량 지정 너무 작으면, 프로듀서가 브로커로 더 자주 보내기 때문에 네트워크 부담이 있고, 너무 크면 메모리를 더많이 사용. 기본 값 16384
linger.ms : 배치를 전송하기 전까지 기다리는 최소시간. 기본값0
partitioner.class : 레코드를 파티션에 전송할 때 적용하는 파티셔너 클래스를 지정. 기본값 org.apache.kafka.clients.producer.internals.DefaultPartitioner
enable.idempotence : 멱등성 프로듀서로 작동할지 여부 설정. 기본 값 false
transactional.id 프로듀서가 레코드를 전송할 때 레코드를 트랜잭션 단위로 묶을지 여부설정. 기본값 null
그외 옵션 http://bit.ly/3aSdIRr

consumer
필수
bootstrap.servers 프로듀서가 데이터를 전송할 대상 카프카 클러스터에 속한 브로커의 호스트 이름: 포트를 1개이상 작성. 2개이상 !
key.deserializer:레코드의 메시지 키를 역직렬화하는 클래스 지정
value.deserializer:레코드의 메시지 값을 역지렬화하는 클래스 지정
선택
group.id: 컨슈머 그룹아이디 지정. subscribe9)메스드로 토픽을 구독하여 사용할 때는 이 옵션을 필수로 넣어야함. 기본 값 null
auto.offset.reset: 컨슈머 그룹이 특정 파티션을 읽을 때 저장된 컨슈머 오프셋이 없는 경우 어느 오프셋부터 읽을지 선택하는 옵션.
이미 컨슈머 오프셋이 있다면 이 옵션값은 무시된다. 이 옵션은 latest, earliest, none 중 1개를 설정. 
latest로 설정하면 가장 높은(가장 최근에 넣은)오프셋 부터 읽기 시작, earliest로 설정하면 가장낮은(가장 오래전에 넣은). none 으로 설정하면 컨슈머 그룹이 커밋한 기록이 있는지 찾아본다.
만약 커밋 기록이 없으면 오류를 반환하고, 커밋기록이 있다마녀 기존커밋 기록 이후 오프셋부터 읽이 시작. 기본값은 latest.
enable.auto.commit : 자동커밋으로 할지 수동 커밋으로 할지 선택 기본값 true.
auto.commit.interval.ms: 자동 커밋(enable.auto.commit=true)일 경우 오프셋 커밋 간격을 지정한다. 기본값은 5000(5초)
max.poll.records: poll() 메서드를 통해 반환되는 레코드 개수를 지정. 기본값은 500
session.timeout.ms: 컨슈머가 브로커와 연결이 끊기는 최대시간. 이사긴 내에 하트비트를 전송하지 않으면 브로커는 컨슈머에 이슈가 발생했다고 가정하고 리밸런싱 시작
보통 하트비트 시간 가격의 3ㅐ로 설정. 기본값 10000(10초)
hearbeat.interval.ms: 하트비트를 전송하는 시간 간격. 기본값 3000(3초)
max.poll.interval.ms: poll() 메서드를 호출하는 간격의 최대시간. poll()메서드를 소출한 이후에 데이터를 처리하는 데에 시간이 너무 많이 걸리는 경우 비정상으로 판단하고 리밸런싱을 시작. 기본값300000(5분)
isolation.level:트랜잭션 프로듀서가 레코드를 트랜잭션 단위로 보낼 경우 사용. 이옵션은 read_committed, read_uncommitted 설정 가능. 
read_committed로 설정하면 커밋이 완료된 레코드만 읽는다. read_uncommitted로 설정하면 커밋 여부와 관계없이 파티션에 있는 모든 레코드를 읽는다. 기본값은 read_uncommitted
그외 http://bit.ly/3aSdIRr

